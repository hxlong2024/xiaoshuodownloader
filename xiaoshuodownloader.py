import streamlit as st
import aiohttp
import asyncio
from bs4 import BeautifulSoup
import re
import zipfile
import io
import time
import urllib.parse
import mimetypes
import datetime
import extra_streamlit_components as stx

# ==========================================
# 1. åŸºç¡€å¼•æ“
# ==========================================

class BaseEngine:
    def __init__(self):
        self.source_name = "æœªçŸ¥æº"
        # æ¨¡æ‹Ÿæœ€æ–° Chrome
        self.headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36",
            "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8",
            "Accept-Language": "zh-CN,zh;q=0.9,en;q=0.8"
        }

    def log(self, msgs, text):
        msgs.append(f"[{self.source_name}] {text}")

    def clean_filename(self, text):
        return re.sub(r'[\\/*?:"<>|]', "", text).strip()

    def validate_title(self, user_keyword, site_title):
        def clean(s): return re.sub(r'[^\w\u4e00-\u9fa5]', '', s).lower()

        return clean(user_keyword) in clean(site_title)

    async def run(self, session, keyword):
        raise NotImplementedError


# ==========================================
# 2. 99å°è¯´ç½‘
# ==========================================
class JJJXSW_Engine(BaseEngine):
    def __init__(self):
        super().__init__()
        self.source_name = "99å°è¯´ç½‘"
        self.base_url = "https://m.jjjxsw.com"
        self.headers["Referer"] = "https://m.jjjxsw.com/"

    async def run(self, session, keyword):
        logs = []
        try:
            self.log(logs, f"ğŸš€ æœç´¢: {keyword}")
            async with session.post(f"{self.base_url}/e/search/index.php",
                                    data={"keyboard": keyword, "Submit22": "æœç´¢", "show": "title"},
                                    headers=self.headers) as resp:
                soup = BeautifulSoup(await resp.text(encoding='utf-8', errors='ignore'), 'html.parser')

            target_item = None;
            target_title = "";
            target_href = "";
            target_author = "ä½šå"
            for item in soup.select(".booklist_a .list_a .main"):
                link = item.find('a')
                if not link: continue
                raw_title = link.get_text().strip()
                if self.validate_title(keyword, raw_title):
                    target_item = item;
                    target_title = raw_title;
                    target_href = link['href']
                    for span in item.find_all('span'):
                        if "ä½œè€…" in span.get_text(): target_author = span.get_text().split(":")[-1].strip(); break
                    break

            if not target_item: return False, None, logs
            self.log(logs, f"âœ… åŒ¹é…: ã€Š{target_title}ã€‹")

            async with session.get(self.base_url + target_href, headers=self.headers) as resp:
                intro_soup = BeautifulSoup(await resp.text(encoding='utf-8', errors='ignore'), 'html.parser')
            confirm_url = None
            sso = intro_soup.select_one(".sso_d")
            if sso:
                for a in sso.find_all('a'):
                    if "ä¸‹è½½" in a.get_text(): confirm_url = a['href']; break
            if not confirm_url:
                t = intro_soup.find('a', string=re.compile("ä¸‹è½½"))
                if t: confirm_url = t['href']
            if not confirm_url: return False, None, logs
            if not confirm_url.startswith("http"): confirm_url = self.base_url + confirm_url

            async with session.get(confirm_url, headers=self.headers) as resp:
                confirm_soup = BeautifulSoup(await resp.text(encoding='utf-8', errors='ignore'), 'html.parser')
            real_link = confirm_soup.find('a', id='id0') or confirm_soup.find('a', href=re.compile(r'doaction\.php'))
            if not real_link: return False, None, logs
            real_url = real_link['href']
            if not real_url.startswith("http"): real_url = self.base_url + real_url

            self.log(logs, "â¬‡ï¸ ä¸‹è½½ä¸­...")
            async with session.get(real_url, headers=self.headers) as resp:
                if resp.status == 200:
                    content = await resp.read()
                    fname = f"{self.clean_filename(target_title)} by {self.clean_filename(target_author)}.txt"
                    return True, {"filename": fname, "author": target_author, "content": content}, logs
            return False, None, logs
        except Exception as e:
            self.log(logs, f"âŒ å¼‚å¸¸: {e}");
            return False, None, logs


# ==========================================
# 3. Z-Library å¼•æ“
# ==========================================
class ZLibrary_Engine(BaseEngine):
    def __init__(self, email, password):
        super().__init__()
        self.source_name = "Z-Library"
        self.base_url = "https://en.zlib.li"
        self.email = email
        self.password = password

    async def login(self, session, logs):
        if not self.email: return False
        self.log(logs, "ğŸ”‘ æ­£åœ¨ç™»å½•...")
        try:
            h = self.headers.copy();
            h["Origin"] = self.base_url;
            h["Referer"] = f"{self.base_url}/login"
            payload = {"email": self.email, "password": self.password, "site_mode": "books", "action": "login",
                       "redirectUrl": self.base_url + "/"}
            async with session.post(f"{self.base_url}/", data=payload, headers=h) as resp:
                text = await resp.text()
                if 'id="loginForm"' in text or "validation-error" in text:
                    self.log(logs, "âŒ ç™»å½•å¤±è´¥")
                    return False
                self.log(logs, "ğŸ”“ ç™»å½•æˆåŠŸ")
                return True
        except Exception as e:
            self.log(logs, f"âŒ ç™»å½•å¼‚å¸¸: {e}");
            return False

    async def run(self, session, keyword):
        logs = []
        if not await self.login(session, logs): return False, None, logs

        try:
            self.log(logs, f"ğŸš€ æœç´¢: {keyword}")
            async with session.get(f"{self.base_url}/s/", params={"q": keyword}, headers=self.headers) as resp:
                soup = BeautifulSoup(await resp.text(errors='ignore'), 'html.parser')

            target_item = None
            target_data = {}

            for item in soup.find_all('z-bookcard'):
                t_div = item.find('div', slot='title')
                title = t_div.get_text().strip() if t_div else ""
                href = item.get('href')

                if self.validate_title(keyword, title) and href:
                    target_item = item
                    target_data = {"title": title, "href": href.strip()}
                    a_div = item.find('div', slot='author')
                    target_data['author'] = a_div.get_text().strip() if a_div else "ä½šå"
                    break

            if not target_item:
                self.log(logs, "âŒ æœªæ‰¾åˆ°åŒ¹é…ä¹¦ç±")
                return False, None, logs

            detail_url = urllib.parse.urljoin(self.base_url, target_data['href'])
            self.log(logs, f"âœ… é”å®š: ã€Š{target_data['title']}ã€‹")
            self.log(logs, f"ğŸ”— ç”Ÿæˆè¯¦æƒ…é¡µé“¾æ¥: {detail_url}")

            return True, {
                "type": "link", 
                "title": target_data['title'],
                "author": target_data['author'],
                "url": detail_url
            }, logs

        except Exception as e:
            self.log(logs, f"âŒ å¼‚å¸¸: {e}");
            return False, None, logs


# ==========================================
# 4. æœç´¢è°ƒåº¦é€»è¾‘
# ==========================================
async def search_race_mode(keyword, zlib_creds):
    engines = [JJJXSW_Engine()] 
    if zlib_creds['email']: engines.append(ZLibrary_Engine(zlib_creds['email'], zlib_creds['password']))

    start = time.time()
    all_logs = []

    timeout = aiohttp.ClientTimeout(total=15)
    connector = aiohttp.TCPConnector(ssl=False)

    async with aiohttp.ClientSession(timeout=timeout, connector=connector) as session:
        tasks = [asyncio.create_task(e.run(session, keyword)) for e in engines]
        for t, e in zip(tasks, engines): t.set_name(e.source_name)

        pending = set(tasks)
        while pending:
            done, pending = await asyncio.wait(pending, return_when=asyncio.FIRST_COMPLETED)
            for task in done:
                success, result, logs = await task
                all_logs.extend(logs)
                if success and result:
                    for p in pending: p.cancel()
                    return {"success": True, "source": task.get_name(), "data": result, "logs": all_logs,
                            "time": time.time() - start}
    return {"success": False, "logs": all_logs, "time": time.time() - start}


# ==========================================
# 5. UI éƒ¨åˆ† (ä¿®å¤äº†ç¬¬ä¸€æ¬¡ç‚¹å‡»æ— æ•ˆçš„é—®é¢˜)
# ==========================================

st.set_page_config(page_title="å…¨èƒ½èµ›é©¬ä¸‹è½½å™¨", page_icon="ğŸ¦„", layout="centered")

# åˆå§‹åŒ– Cookie ç®¡ç†å™¨
cookie_manager = stx.CookieManager()

st.markdown(
    """
    <style>
    .block-container {
        padding-top: 0rem !important;
        padding-bottom: 1rem !important;
    }
    .stButton>button{width:100%;border-radius:8px;font-weight:bold}
    .success-box{padding:15px;background:#e6fffa;border:1px solid #38b2ac;color:#234e52;border-radius:8px}
    .link-box{padding:15px;background:#ebf8ff;border:1px solid #4299e1;color:#2b6cb0;border-radius:8px;text-align:center;}
    .link-box a {color: #2b6cb0; font-weight: bold; font-size: 1.2em; text-decoration: none;}
    </style>
    """,
    unsafe_allow_html=True)


st.title("")
st.caption("å¹¶å‘æ£€ç´¢ï¼š99å°è¯´ | Z-Library")

# === ä¾§è¾¹æ ï¼šCookie è´¦å·ç®¡ç† (æ— æ‰“æ–­æ¨¡å¼) ===
with st.sidebar:
    st.header("ğŸ”‘ Z-Library")
    
    # 1. åˆå§‹åŒ–æ ‡è®°
    if "cookie_initialized" not in st.session_state:
        st.session_state["cookie_initialized"] = False

    # 2. è¯»å– Cookie
    cookies = cookie_manager.get_all()
    
    # 3. æ ¸å¿ƒä¿®å¤ï¼šå¡«å……ä½†ä¸åˆ·æ–° (NO RERUN)
    # è¿™æ­¥æ“ä½œå¿…é¡»åœ¨ text_input åˆ›å»ºä¹‹å‰å®Œæˆ
    if not st.session_state["cookie_initialized"] and cookies:
        c_email = cookies.get("zlib_email")
        c_pass = cookies.get("zlib_pass")
        
        # åªè¦ Cookie æœ‰å€¼ï¼Œä¸” session_state æ˜¯ç©ºçš„ï¼Œå°±å¡«è¿›å»
        # è¿™ä¼šç›´æ¥å½±å“åé¢ input_email çš„åˆå§‹å€¼
        if c_email and "z_email_input" not in st.session_state:
            st.session_state["z_email_input"] = c_email
        if c_pass and "z_pass_input" not in st.session_state:
            st.session_state["z_pass_input"] = c_pass
        
        # æ ‡è®°ä¸ºå·²åˆå§‹åŒ–
        st.session_state["cookie_initialized"] = True
        
        # âš¡ å…³é”®æ”¹åŠ¨ï¼šè¿™é‡Œåˆ é™¤äº† st.rerun()
        # è¿™æ ·å°±ä¸ä¼šæ‰“æ–­ä½ çš„â€œæé€Ÿæ£€ç´¢â€ç‚¹å‡»äº‹ä»¶äº†ï¼
        # è™½ç„¶ç•Œé¢å¯èƒ½ä¸ä¼šåœ¨é‚£ä¸€ç¬é—´é—ªçƒåˆ·æ–°ï¼Œä½†å˜é‡å·²ç»è¢«èµ‹å€¼äº†ã€‚
        st.toast("âœ… å·²è‡ªåŠ¨åŠ è½½è´¦å·", icon="ğŸª")

    # 4. æ˜¾ç¤ºè¾“å…¥æ¡† (ä¼šè‡ªåŠ¨ä» session_state è¯»å–åˆšåˆšå¡«å…¥çš„å€¼)
    input_email = st.text_input("Email", key="z_email_input")
    input_pass = st.text_input("Password", type="password", key="z_pass_input")

    # 5. ä¿å­˜æŒ‰é’®
    if st.button("ğŸ’¾ è®°ä½æˆ‘çš„è´¦å·"):
        expires = datetime.datetime.now() + datetime.timedelta(days=30)
        cookie_manager.set("zlib_email", input_email, expires_at=expires, key="set_email_cookie")
        cookie_manager.set("zlib_pass", input_pass, expires_at=expires, key="set_pass_cookie")
        st.success("âœ… å·²ä¿å­˜ï¼")
        time.sleep(1.5) 
        st.rerun()

    # 6. æ¸…é™¤æŒ‰é’®
    if st.button("ğŸ—‘ï¸ å¿˜è®°è´¦å·"):
        cookie_manager.delete("zlib_email", key="del_email_cookie")
        cookie_manager.delete("zlib_pass", key="del_pass_cookie")
        st.session_state["z_email_input"] = ""
        st.session_state["z_pass_input"] = ""
        st.session_state["cookie_initialized"] = False
        st.rerun()

# === ä¸»ç•Œé¢é€»è¾‘ ===
keyword = st.text_input("ä¹¦å", placeholder="ä¾‹å¦‚ï¼šå¯æ€œçš„ç¤¾ç•œ")
if st.button("ğŸš€ æé€Ÿæ£€ç´¢", type="primary"):
    if not keyword:
        st.warning("è¯·è¾“å…¥ä¹¦å")
    else:
        # ä½¿ç”¨å½“å‰è¾“å…¥æ¡†çš„å€¼è¿›è¡Œæœç´¢
        st.info("ğŸ” å…¨ç½‘å¹¶å‘æ£€ç´¢ä¸­...")
        res = asyncio.run(search_race_mode(keyword, {'email': input_email, 'password': input_pass}))

        if res["success"]:
            d = res['data']

            # æƒ…å†µ A: é“¾æ¥ (Z-Lib)
            if d.get("type") == "link":
                st.markdown(
                    f"""
                    <div class='link-box'>
                        <h3>ğŸ•µï¸â€â™‚ï¸ å·²æ‰¾åˆ°ä¹¦ç±/è¯¦æƒ…é¡µ</h3>
                        <p><b>{d['title']}</b><br>ä½œè€…: {d['author']}</p>
                        <hr style="margin:10px 0; border:0; border-top:1px solid #bbeeef;">
                        <p>è¯·ç‚¹å‡»ä¸‹æ–¹é“¾æ¥å»æµè§ˆå™¨é˜…è¯»æˆ–ä¸‹è½½ï¼š</p>
                        <a href="{d['url']}" target="_blank">ğŸ‘‰ ç‚¹å‡»æ‰“å¼€: {d['title']} ğŸ‘ˆ</a>
                    </div>
                    """,
                    unsafe_allow_html=True
                )
                st.text_input("æˆ–å¤åˆ¶æ­¤é“¾æ¥:", d['url'])
                st.caption(f"æ¥æº: {res['source']} (è€—æ—¶ {res['time']:.2f}s)")

            # æƒ…å†µ B: æ–‡ä»¶ (99å°è¯´ç½‘)
            elif "content" in d:
                st.markdown(
                    f"<div class='success-box'><h3>âœ… æ–‡ä»¶è·å–æˆåŠŸ!</h3><b>{d['filename']}</b><br>æº: {res['source']} ({res['time']:.2f}s)</div>",
                    unsafe_allow_html=True)

                mime = "application/octet-stream"
                if d['filename'].endswith(".pdf"):
                    mime = "application/pdf"
                elif d['filename'].endswith(".epub"):
                    mime = "application/epub+zip"
                elif d['filename'].endswith(".txt"):
                    mime = "text/plain"

                c1, c2 = st.columns(2)
                c1.download_button(f"ğŸ“¥ ä¸‹è½½ ({d['filename'].split('.')[-1]})", d['content'], d['filename'], mime=mime)

                buf = io.BytesIO()
                with zipfile.ZipFile(buf, "a", zipfile.ZIP_DEFLATED, False) as zf:
                    zf.writestr(d['filename'], d['content'])
                c2.download_button("ğŸ“¦ ä¸‹è½½ZIP", buf.getvalue(), d['filename'] + ".zip", "application/zip")

        else:
            st.error("ğŸ˜­ å…¨ç½‘æœªæ‰¾åˆ°èµ„æº")

        with st.expander("æŸ¥çœ‹æ‰§è¡Œæ—¥å¿—"):
            for m in res["logs"]: st.text(m)
