import streamlit as st
import aiohttp
import asyncio
from bs4 import BeautifulSoup
import re
import zipfile
import io
import time
import urllib.parse
import mimetypes

# ==========================================
# 1. åŸºç¡€å¼•æ“ (ä¿æŒä¸å˜)
# ==========================================

class BaseEngine:
    def __init__(self):
        self.source_name = "æœªçŸ¥æº"
        # æ¨¡æ‹Ÿæœ€æ–° Chrome
        self.headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36",
            "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8",
            "Accept-Language": "zh-CN,zh;q=0.9,en;q=0.8"
        }

    def log(self, msgs, text):
        msgs.append(f"[{self.source_name}] {text}")

    def clean_filename(self, text):
        return re.sub(r'[\\/*?:"<>|]', "", text).strip()

    def validate_title(self, user_keyword, site_title):
        def clean(s): return re.sub(r'[^\w\u4e00-\u9fa5]', '', s).lower()
        return clean(user_keyword) in clean(site_title)

    async def run(self, session, keyword):
        raise NotImplementedError

# ==========================================
# 2. 99å°è¯´ç½‘ (ä¿æŒä¸å˜)
# ==========================================
class JJJXSW_Engine(BaseEngine):
    def __init__(self):
        super().__init__()
        self.source_name = "99å°è¯´ç½‘"
        self.base_url = "https://m.jjjxsw.com"
        self.headers["Referer"] = "https://m.jjjxsw.com/"

    async def run(self, session, keyword):
        logs = []
        try:
            self.log(logs, f"ğŸš€ æœç´¢: {keyword}")
            async with session.post(f"{self.base_url}/e/search/index.php",
                                    data={"keyboard": keyword, "Submit22": "æœç´¢", "show": "title"},
                                    headers=self.headers) as resp:
                soup = BeautifulSoup(await resp.text(encoding='utf-8', errors='ignore'), 'html.parser')

            target_item = None; target_title = ""; target_href = ""; target_author = "ä½šå"
            for item in soup.select(".booklist_a .list_a .main"):
                link = item.find('a')
                if not link: continue
                raw_title = link.get_text().strip()
                if self.validate_title(keyword, raw_title):
                    target_item = item; target_title = raw_title; target_href = link['href']
                    for span in item.find_all('span'):
                        if "ä½œè€…" in span.get_text(): target_author = span.get_text().split(":")[-1].strip(); break
                    break

            if not target_item: return False, None, logs
            self.log(logs, f"âœ… åŒ¹é…: ã€Š{target_title}ã€‹")

            async with session.get(self.base_url + target_href, headers=self.headers) as resp:
                intro_soup = BeautifulSoup(await resp.text(encoding='utf-8', errors='ignore'), 'html.parser')
            confirm_url = None
            sso = intro_soup.select_one(".sso_d")
            if sso:
                for a in sso.find_all('a'):
                    if "ä¸‹è½½" in a.get_text(): confirm_url = a['href']; break
            if not confirm_url:
                t = intro_soup.find('a', string=re.compile("ä¸‹è½½"))
                if t: confirm_url = t['href']
            if not confirm_url: return False, None, logs
            if not confirm_url.startswith("http"): confirm_url = self.base_url + confirm_url

            async with session.get(confirm_url, headers=self.headers) as resp:
                confirm_soup = BeautifulSoup(await resp.text(encoding='utf-8', errors='ignore'), 'html.parser')
            real_link = confirm_soup.find('a', id='id0') or confirm_soup.find('a', href=re.compile(r'doaction\.php'))
            if not real_link: return False, None, logs
            real_url = real_link['href']
            if not real_url.startswith("http"): real_url = self.base_url + real_url

            self.log(logs, "â¬‡ï¸ ä¸‹è½½ä¸­...")
            async with session.get(real_url, headers=self.headers) as resp:
                if resp.status == 200:
                    content = await resp.read()
                    fname = f"{self.clean_filename(target_title)} by {self.clean_filename(target_author)}.txt"
                    return True, {"filename": fname, "author": target_author, "content": content}, logs
            return False, None, logs
        except Exception as e:
            self.log(logs, f"âŒ å¼‚å¸¸: {e}");
            return False, None, logs

# ==========================================
# 3. Z-Library å¼•æ“
# ==========================================
class ZLibrary_Engine(BaseEngine):
    def __init__(self, email, password):
        super().__init__()
        self.source_name = "Z-Library"
        self.base_url = "https://en.zlib.li"
        self.email = email
        self.password = password

    async def login(self, session, logs):
        if not self.email: return False
        self.log(logs, "ğŸ”‘ æ­£åœ¨ç™»å½•...")
        try:
            h = self.headers.copy();
            h["Origin"] = self.base_url;
            h["Referer"] = f"{self.base_url}/login"
            payload = {"email": self.email, "password": self.password, "site_mode": "books", "action": "login",
                       "redirectUrl": self.base_url + "/"}
            async with session.post(f"{self.base_url}/", data=payload, headers=h) as resp:
                text = await resp.text()
                if 'id="loginForm"' in text or "validation-error" in text:
                    self.log(logs, "âŒ ç™»å½•å¤±è´¥")
                    return False
                self.log(logs, "ğŸ”“ ç™»å½•æˆåŠŸ")
                return True
        except Exception as e:
            self.log(logs, f"âŒ ç™»å½•å¼‚å¸¸: {e}");
            return False

    async def run(self, session, keyword):
        logs = []
        if not await self.login(session, logs): return False, None, logs

        try:
            self.log(logs, f"ğŸš€ æœç´¢: {keyword}")
            async with session.get(f"{self.base_url}/s/", params={"q": keyword}, headers=self.headers) as resp:
                soup = BeautifulSoup(await resp.text(errors='ignore'), 'html.parser')

            target_item = None
            target_data = {}

            for item in soup.find_all('z-bookcard'):
                t_div = item.find('div', slot='title')
                title = t_div.get_text().strip() if t_div else ""
                href = item.get('href')

                if self.validate_title(keyword, title) and href:
                    target_item = item
                    target_data = {"title": title, "href": href.strip()}
                    a_div = item.find('div', slot='author')
                    target_data['author'] = a_div.get_text().strip() if a_div else "ä½šå"
                    break

            if not target_item:
                self.log(logs, "âŒ æœªæ‰¾åˆ°åŒ¹é…ä¹¦ç±")
                return False, None, logs

            detail_url = urllib.parse.urljoin(self.base_url, target_data['href'])
            self.log(logs, f"âœ… é”å®š: ã€Š{target_data['title']}ã€‹")
            self.log(logs, f"ğŸ”— ç”Ÿæˆè¯¦æƒ…é¡µé“¾æ¥: {detail_url}")

            return True, {
                "type": "link", 
                "title": target_data['title'],
                "author": target_data['author'],
                "url": detail_url
            }, logs

        except Exception as e:
            self.log(logs, f"âŒ å¼‚å¸¸: {e}");
            return False, None, logs

# ==========================================
# 4. æœç´¢è°ƒåº¦é€»è¾‘
# ==========================================
async def search_race_mode(keyword, zlib_creds):
    engines = [JJJXSW_Engine()] 
    if zlib_creds['email']: engines.append(ZLibrary_Engine(zlib_creds['email'], zlib_creds['password']))

    start = time.time()
    all_logs = []

    timeout = aiohttp.ClientTimeout(total=15)
    connector = aiohttp.TCPConnector(ssl=False)

    async with aiohttp.ClientSession(timeout=timeout, connector=connector) as session:
        tasks = [asyncio.create_task(e.run(session, keyword)) for e in engines]
        for t, e in zip(tasks, engines): t.set_name(e.source_name)

        pending = set(tasks)
        while pending:
            done, pending = await asyncio.wait(pending, return_when=asyncio.FIRST_COMPLETED)
            for task in done:
                success, result, logs = await task
                all_logs.extend(logs)
                if success and result:
                    for p in pending: p.cancel()
                    return {"success": True, "source": task.get_name(), "data": result, "logs": all_logs,
                            "time": time.time() - start}
    return {"success": False, "logs": all_logs, "time": time.time() - start}

# ==========================================
# 5. UI éƒ¨åˆ† (V17.0 å›å½’ä¸¤è¡Œç¨³å®šç‰ˆ)
# ==========================================

st.set_page_config(page_title="å…¨èƒ½èµ›é©¬ä¸‹è½½å™¨", page_icon="ğŸ¦„", layout="centered")

st.markdown(
    """
    <style>
    .block-container {padding-top: 0rem !important; padding-bottom: 1rem !important;}
    .stButton>button{width:100%;border-radius:8px;font-weight:bold}
    .success-box{padding:15px;background:#e6fffa;border:1px solid #38b2ac;color:#234e52;border-radius:8px}
    .link-box{padding:15px;background:#ebf8ff;border:1px solid #4299e1;color:#2b6cb0;border-radius:8px;text-align:center;}
    .link-box a {color: #2b6cb0; font-weight: bold; font-size: 1.2em; text-decoration: none;}
    
    /* è°ƒæ•´æ¸…é™¤æŒ‰é’®é¢œè‰² */
    div[data-testid="stForm"] button[kind="secondary"] {border-color: #ffccc7; color: #cf1322;}
    div[data-testid="stForm"] button[kind="secondary"]:hover {border-color: #ff7875; color: #a8071a; background-color: #fff1f0;}
    </style>
    """,
    unsafe_allow_html=True)

st.title("")
st.caption("å¹¶å‘æ£€ç´¢ï¼š99å°è¯´ | Z-Library")

# === ä¾§è¾¹æ ï¼šURL ä¼ å‚ä¿å­˜æ³• ===
with st.sidebar:
    st.header("ğŸ”‘ Z-Library è´¦å·")
    st.caption("ğŸ‘‡ å¡«å¥½è´¦å·åç‚¹å‡»ä¿å­˜ï¼Œç„¶åã€æ”¶è—æµè§ˆå™¨ä¹¦ç­¾ã€‘å³å¯ã€‚")
    
    params = st.query_params
    default_email = params.get("email", "")
    default_pass = params.get("pass", "")
    
    s_email = st.text_input("Email", value=default_email, key="sb_email")
    s_pass = st.text_input("Password", value=default_pass, type="password", key="sb_pass")
    
    if st.button("ğŸ”— ç”Ÿæˆä¿å­˜é“¾æ¥"):
        st.query_params["email"] = s_email
        st.query_params["pass"] = s_pass
        st.success("âœ… é“¾æ¥å·²ç”Ÿæˆï¼è¯·æ”¶è—å½“å‰ç½‘é¡µã€‚")
        time.sleep(1)

# === å›è°ƒå‡½æ•° (æ¸…é™¤çŠ¶æ€) ===
def clear_input():
    st.session_state["search_keyword"] = ""

# === ä¸»ç•Œé¢é€»è¾‘ ===

if "search_keyword" not in st.session_state:
    st.session_state["search_keyword"] = ""

with st.form("search_form"):
    keyword = st.text_input("ä¹¦å", placeholder="è¯·æ‰‹åŠ¨ç²˜è´´ä¹¦å...", key="search_keyword")
    
    # æ¯”ä¾‹è®¾ä¸º 1:1
    # åœ¨ç”µè„‘ä¸Šï¼Œè¿™æ˜¯å·¦å³å¹¶æ’
    # åœ¨æ‰‹æœºä¸Šï¼ŒStreamlit ä¼šè‡ªåŠ¨æŠŠå®ƒä»¬æ‹†æˆä¸Šä¸‹ä¸¤è¡Œ (è¿™å°±æ˜¯ä½ è¦çš„æ•ˆæœ)
    c1, c2 = st.columns([1, 1])
    
    with c1:
        is_submitted = st.form_submit_button("ğŸš€ æé€Ÿæ£€ç´¢", type="primary")
    with c2:
        # åŠ ä¸Š on_click å›è°ƒï¼Œç¡®ä¿æ¸…é™¤åŠŸèƒ½æ­£å¸¸ä¸”ä¸æŠ¥é”™
        st.form_submit_button("ğŸ§¹ ä¸€é”®æ¸…é™¤", type="secondary", on_click=clear_input)

# === é€»è¾‘å¤„ç† ===

if is_submitted:
    if not keyword:
        st.warning("è¯·è¾“å…¥ä¹¦å")
    else:
        st.info("ğŸ” å…¨ç½‘å¹¶å‘æ£€ç´¢ä¸­...")
        res = asyncio.run(search_race_mode(keyword, {'email': s_email, 'password': s_pass}))

        if res["success"]:
            d = res['data']

            # æƒ…å†µ A: é“¾æ¥ (Z-Lib)
            if d.get("type") == "link":
                st.markdown(
                    f"""
                    <div class='link-box'>
                        <h3>ğŸ•µï¸â€â™‚ï¸ å·²æ‰¾åˆ°ä¹¦ç±/è¯¦æƒ…é¡µ</h3>
                        <p><b>{d['title']}</b><br>ä½œè€…: {d['author']}</p>
                        <hr style="margin:10px 0; border:0; border-top:1px solid #bbeeef;">
                        <p>è¯·ç‚¹å‡»ä¸‹æ–¹é“¾æ¥å»æµè§ˆå™¨é˜…è¯»æˆ–ä¸‹è½½ï¼š</p>
                        <a href="{d['url']}" target="_blank">ğŸ‘‰ ç‚¹å‡»æ‰“å¼€: {d['title']} ğŸ‘ˆ</a>
                    </div>
                    """,
                    unsafe_allow_html=True
                )
                st.text_input("æˆ–å¤åˆ¶æ­¤é“¾æ¥:", d['url'])
                st.caption(f"æ¥æº: {res['source']} (è€—æ—¶ {res['time']:.2f}s)")

            # æƒ…å†µ B: æ–‡ä»¶ (99å°è¯´ç½‘)
            elif "content" in d:
                st.markdown(
                    f"<div class='success-box'><h3>âœ… æ–‡ä»¶è·å–æˆåŠŸ!</h3><b>{d['filename']}</b><br>æº: {res['source']} ({res['time']:.2f}s)</div>",
                    unsafe_allow_html=True)

                mime = "application/octet-stream"
                if d['filename'].endswith(".pdf"): mime = "application/pdf"
                elif d['filename'].endswith(".epub"): mime = "application/epub+zip"
                elif d['filename'].endswith(".txt"): mime = "text/plain"

                c1, c2 = st.columns(2)
                c1.download_button(f"ğŸ“¥ ä¸‹è½½ ({d['filename'].split('.')[-1]})", d['content'], d['filename'], mime=mime)

                buf = io.BytesIO()
                with zipfile.ZipFile(buf, "a", zipfile.ZIP_DEFLATED, False) as zf:
                    zf.writestr(d['filename'], d['content'])
                c2.download_button("ğŸ“¦ ä¸‹è½½ZIP", buf.getvalue(), d['filename'] + ".zip", "application/zip")

        else:
            st.error("ğŸ˜­ å…¨ç½‘æœªæ‰¾åˆ°èµ„æº")
            if not s_email:
                st.warning("æç¤ºï¼šä¾§è¾¹æ æœªå¡« Z-Library è´¦å·ï¼Œä»…æœç´¢äº†å…è´¹æºã€‚")

        with st.expander("æŸ¥çœ‹æ‰§è¡Œæ—¥å¿—"):
            for m in res["logs"]: st.text(m)
